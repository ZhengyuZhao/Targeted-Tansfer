## About
PyTorch code for our arXiv article:

Zhengyu Zhao, Zhuoran Liu, Martha Larson, [**"On Success and Simplicity: A Second Look at Transferable Targeted Attacks"**](http://arxiv.org/abs/2012.11207), 2020.
<!-- <p align="center">
  <img src="https://github.com/ZhengyuZhao/color_adversarial/blob/master/figures/figure1.PNG" width='600'>
</p> -->
We take a second look at the transferability of targeted attacks and show that their difficulty has been overestimated due to a blind spot in the conventional evaluation procedures.
Specifically, current work has unreasonably restricted attack optimization to a few iterations.
Here, we show that targeted attacks converge slowly to optimal transferability and improve considerably when given more iterations.
We also show that a simple logit attack performs surprisingly well, remarkably surpassing more complex losses and even achieving performance
comparable to the state of the art, which requires massive training with sophisticated loss.
Additional experiments on attacking the Google Cloud Vision API and creating targeted Universal Adaversarial Perturbations (UAP) are also conducted.

## Implementation

### Overview

This code contains the implementations of:
 1. Transferable targeted attacks in both the single model transfer setting and the ensemble transfer setting. 
 2. Creating targeted UAP by our new logit attack.
 
### Requirements
torch>=1.7.0; torchvision>=0.8.1; tqdm>=4.31.1; pillow>=7.0.0; matplotlib>=3.2.2;  numpy>=1.18.1; 

### Dataset

The 1000 images of the ImageNet-Compatible dataset are provided in the folder ```dataset/images```, along with their descriptions in  ```dataset/images.csv```, including their URLs, cropping bounding boxes, classification labels and some other metadata. More details on this dataset can be found in [its official repository](https://github.com/tensorflow/cleverhans/blob/master/examples/nips17_adversarial_competition/dataset).

### Experiments
Code for all the experiments with comments can be found in the Jupyter Notebook file ```main.ipynb```.

### Results
#### For all experiments, L<sub>&infin;</sub>=16 is applied.

Results of the single model transfer setting:
<p align="center">
  <img src="https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/Figures/transfer_single.PNG" width='700'>
</p>


Results of the ensemble model transfer setting:
<p align="center">
  <img src="https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/Figures/transfer_ensemble.PNG" width='700'>
</p>

Examples of the transferable targeted adversarial images from ResNet50 to DenseNet121 generated by our logit attack:
<p align="center">
  <img src="https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/Figures/vis.PNG" width='400'>
</p>


Examples of attacking the Google Cloud Vision API using our logit attack:
<p align="center">
  <img src="https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/Figures/google.PNG" width='400'>
</p>


Examples of the targeted UAP generated by our logit attack:
<p align="center">
  <img src="https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/Figures/uap.PNG" width='400'>
</p>
